{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Training and Evaluation of Logistic Regression on Encrypted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "from time import sleep\n",
    "\n",
    "# those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import psutil\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "\n",
    "# torch.random.manual_seed(11)\n",
    "# random.seed(11)\n",
    "# np.random.seed(11) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cic_dataset():\n",
    "    save_list = [\"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
    "    \n",
    "    for i in save_list:\n",
    "        save_path = '/home/cselab/III_TENSEAL_project_III/data/' + i+'.csv'\n",
    "        globals()[\"{}\".format(i)] = pd.read_csv(save_path)\n",
    "    \n",
    "    x_tra = torch.tensor(X_train.values).float()\n",
    "    y_tra = torch.tensor(y_train.values).float()\n",
    "    x_te = torch.tensor(X_test.values).float()\n",
    "    y_te = torch.tensor(y_test.values).float()\n",
    "    \n",
    "    print(\"############# Data summary #############\")\n",
    "    print(f\"x_train has shape: {x_tra.shape}\")\n",
    "    print(f\"y_train has shape: {y_tra.shape}\")\n",
    "    print(f\"x_test has shape: {x_te.shape}\")\n",
    "    print(f\"y_test has shape: {y_te.shape}\")\n",
    "    print(\"#######################################\")\n",
    "    return x_tra, y_tra, x_te, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset():\n",
    "    save_path = '/home/cselab/III_TENSEAL_project_III/data/test_clear3.csv'\n",
    "    data = pd.read_csv(save_path)\n",
    "    print(data.shape)\n",
    "    \n",
    "    y = data['Label']\n",
    "    X = data[:]\n",
    "    X = X.drop(labels='Label',axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        shuffle=True, random_state=34)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "    scaler.fit(X_train)\n",
    "    transformed_X_train = scaler.transform(X_train)\n",
    "    transformed_X_test = scaler.transform(X_test) \n",
    "    \n",
    "    x_train = torch.tensor(transformed_X_train).float()\n",
    "    y_train = torch.tensor(y_train.values).float()\n",
    "    x_test = torch.tensor(transformed_X_test).float()\n",
    "    y_test = torch.tensor(y_test.values).float()\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    \n",
    "    print(\"############# Data summary #############\")\n",
    "    print(f\"x_train has shape: {x_train.shape}\")\n",
    "    print(f\"y_train has shape: {y_train.shape}\")\n",
    "    print(f\"x_test has shape: {x_test.shape}\")\n",
    "    print(f\"y_test has shape: {y_test.shape}\")\n",
    "    print(\"#######################################\")\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([961, 291])\n",
      "y_train has shape: torch.Size([961, 1])\n",
      "x_test has shape: torch.Size([241, 291])\n",
      "y_test has shape: torch.Size([241, 1])\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "# select dataset\n",
    "x_train, y_train, x_test, y_test = cic_dataset()\n",
    "# x_train, y_train, x_test, y_test = test_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "mem_buff = {}\n",
    "mem_flag = [True]\n",
    "\n",
    "def record_mem():    \n",
    "    global mem_buff, st\n",
    "    while mem_flag[0]:\n",
    "        p = psutil.Process()\n",
    "        rss = p.memory_info().rss/2**20        \n",
    "        mem_buff[time()-st] = (rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usage(message: str = 'debug'):\n",
    "    # current process RAM usage\n",
    "    p2 = psutil.Process()\n",
    "    rss = p2.memory_info().rss / 2 ** 20 # Bytes to MB\n",
    "    # print(f\"[{message}] memory usage: {rss: 10.5f} MB\")\n",
    "    return rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model\n",
    "\n",
    "We will start by training a logistic regression model (without any encryption), which can be viewed as a single layer neural network with a single node. We will be using this model as a means of comparison against encrypted training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = LR(n_features)\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_time :  0.06502294540405273\n",
      "====================\n",
      "LR_mem mean :  3.96875\n",
      "LR_mem sum :  3.96875\n",
      "LR_mem max :  3.96875    LR_mem min :  3.96875\n",
      "LR_mem :  [3.96875]\n",
      "====================\n",
      "LR_mem_sub :  509.5390625\n",
      "LR_mem_first :  505.25\n",
      "LR_mem_last :  509.5390625\n",
      "LR_mem_sub :  [509.5390625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define the number of epochs for both plain and encrypted training\n",
    "EPOCHS = 5\n",
    "\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        # print(y.shape)\n",
    "        # print(out.shape)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # print(f\"Loss at epoch {e}: {loss.data}\")\n",
    "    return model\n",
    "\n",
    "LR_time = []\n",
    "LR_mem = []\n",
    "LR_mem_sub = []\n",
    "\n",
    "sfm_s = memory_usage()\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "    mem_buff = {}\n",
    "    mem_flag[0] = True\n",
    "    st = time()\n",
    "    t = threading.Thread(target = record_mem)\n",
    "    t.start()\n",
    "    \n",
    "    \n",
    "    sleep(0.0001)\n",
    "    model = train(model, optim, criterion, x_train, y_train)\n",
    "    sleep(0.0001)\n",
    "    \n",
    "    \n",
    "    et = time()\n",
    "    mem_flag[0] = False\n",
    "    t.join()\n",
    "    ft = et-st\n",
    "    fm = mem_buff[max(mem_buff)]-mem_buff[min(mem_buff)]\n",
    "    # print(\"time : \", et-st)\n",
    "    # print(\"memory : \", mem_buff[max(mem_buff)]-mem_buff[min(mem_buff)])\n",
    "    fm_s = memory_usage()\n",
    "    LR_time.append(ft)\n",
    "    LR_mem.append(fm)\n",
    "    LR_mem_sub.append(fm_s)\n",
    "# plt.title(\"Memory Tracing\")\n",
    "# plt.ylabel(\"Memory_usage\")\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.plot(mem_buff.keys(), [mem_buff[i] for i in mem_buff.keys()])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "print(\"LR_time : \", np.mean(LR_time))\n",
    "print(\"====================\")\n",
    "print(\"LR_mem mean : \", np.mean(LR_mem))\n",
    "print(\"LR_mem sum : \", np.sum(LR_mem))\n",
    "print(\"LR_mem max : \", max(LR_mem), \"   LR_mem min : \", min(LR_mem))\n",
    "print(\"LR_mem : \", LR_mem)\n",
    "\n",
    "print(\"====================\")\n",
    "print(\"LR_mem_sub : \", np.mean(LR_mem_sub))\n",
    "print(\"LR_mem_first : \", sfm_s )\n",
    "print(\"LR_mem_last : \", LR_mem_sub[-1])\n",
    "print(\"LR_mem_sub : \", LR_mem_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on plain test_set: 1.0\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an Encrypted Logistic Regression Model on Encrypted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enc training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        # print(self.weight)\n",
    "        # print(self.bias)\n",
    "        # we accumulate gradients and counts the number of iterations\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        self._delta_w += enc_x * out_minus_y\n",
    "        self._delta_b += out_minus_y\n",
    "        self._count += 1\n",
    "        \n",
    "    def update_parameters(self):\n",
    "        if self._count == 0:\n",
    "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
    "        # update weights\n",
    "        # We use a small regularization term to keep the output\n",
    "        # of the linear layer in the range of the sigmoid approximation\n",
    "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # reset gradient accumulators and iterations count\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        # print(\"weight : \", self.weight.decrypt() , \"bias : \", self.bias.decrypt())\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # We use the polynomial approximation of degree 3\n",
    "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
    "        # from https://eprint.iacr.org/2018/462.pdf\n",
    "        # which fits the function pretty well in the range [-5,5]\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "    \n",
    "    def plain_accuracy(self, x_test, y_test):\n",
    "        # evaluate accuracy of the model on\n",
    "        # the plain (x_test, y_test) dataset\n",
    "        w = torch.tensor(self.weight)\n",
    "        b = torch.tensor(self.bias)\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        # print(out)\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:29<00:00, 29.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_time :  29.161460161209106\n",
      "====================\n",
      "LR_mem mean :  2661.72265625\n",
      "LR_mem sum :  2661.72265625\n",
      "LR_mem max :  2661.72265625    LR_mem min :  2661.72265625\n",
      "LR_mem :  [2661.72265625]\n",
      "====================\n",
      "LR_mem_sub :  3545.26953125\n",
      "LR_mem_first :  881.125\n",
      "LR_mem_last :  3545.26953125\n",
      "LR_mem_sub :  [3545.26953125]\n"
     ]
    }
   ],
   "source": [
    "mem_buff = {}\n",
    "mem_flag[0] = True\n",
    "\n",
    "LR_time = []\n",
    "LR_mem = []\n",
    "LR_mem_sub = []\n",
    "\n",
    "sfm_s = memory_usage()\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "    st = time()\n",
    "    t = threading.Thread(target = record_mem)\n",
    "    t.start()\n",
    "    \n",
    "    enc_x_train11 = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
    "    enc_y_train11 = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
    "    \n",
    "    et = time()\n",
    "    mem_flag[0] = False\n",
    "    t.join()\n",
    "\n",
    "    ft = et-st\n",
    "    fm = mem_buff[max(mem_buff)]-mem_buff[min(mem_buff)]\n",
    "    fm_s = memory_usage()\n",
    "    LR_time.append(ft)\n",
    "    LR_mem.append(fm)\n",
    "    LR_mem_sub.append(fm_s)\n",
    "\n",
    "\n",
    "print(\"LR_time : \", np.mean(LR_time))\n",
    "print(\"====================\")\n",
    "print(\"LR_mem mean : \", np.mean(LR_mem))\n",
    "print(\"LR_mem sum : \", np.sum(LR_mem))\n",
    "print(\"LR_mem max : \", max(LR_mem), \"   LR_mem min : \", min(LR_mem))\n",
    "print(\"LR_mem : \", LR_mem)\n",
    "\n",
    "print(\"====================\")\n",
    "print(\"LR_mem_sub : \", np.mean(LR_mem_sub))\n",
    "print(\"LR_mem_first : \", sfm_s )\n",
    "print(\"LR_mem_last : \", LR_mem_sub[-1])\n",
    "print(\"LR_mem_sub : \", LR_mem_sub)\n",
    "\n",
    "\n",
    "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
    "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution on plain data:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApaElEQVR4nO3de3BU9f3/8fduQjYgSbgTIuGqglzFC/kF6hUUKVqxHaqUVkopKo0XhDqazu9rRL8aVAa1lgF0FJzxgtIpaq3CD63AKBchQBUEBMolyK1qSQLKJtn9/P5I9uRscnbhfM7uZjfn+ZjZMXv2nN3PyTHJi8/nfT4fj1JKCQAAQAx4m7sBAACg5SBYAACAmCFYAACAmCFYAACAmCFYAACAmCFYAACAmCFYAACAmCFYAACAmElP9AcGg0E5cuSIZGVlicfjSfTHAwAADUopqaqqkry8PPF6I/dLJDxYHDlyRPLz8xP9sQAAIAbKy8ule/fuEV9PeLDIysoSkbqGZWdnJ/rjAQCAhsrKSsnPzzf+jkeS8GARGv7Izs4mWAAAkGLOVsZA8SYAAIgZggUAAIgZggUAAIgZggUAAIgZggUAAIgZggUAAIgZggUAAIgZggUAAIgZggUAAIgZggUAAIgZggUAAIgZggUAAIgZggUAx9Z+/R9Z+vmh5m4GgCSQ8NVNAbQsJ3+oljte+VxERAr7dpSeHc9r5hYBaE70WABw5NtT1cbXFT/WNGNLACQDggUAR2qDQePr6tpglD0BuAHBAoAjtQFlfO0nWACuR7AA4EhNgB4LAA1sB4tvvvlGfv3rX0vHjh2ldevWMnjwYNm8eXM82gYgBQSC5h6LQDO2BEAysHVXyH//+18ZOXKkXHvttfLhhx9K586dZc+ePdK+fft4tQ9AkqthKASAia1g8dRTT0l+fr4sXrzY2Na7d++YNwpA6jAXbxIsANgaCnnvvffk8ssvlwkTJkiXLl1k2LBh8tJLL0U9xu/3S2VlZdgDQMthLt4011sAcCdbweLf//63LFiwQC688EJZuXKlTJ8+Xe677z559dVXIx5TWloqOTk5xiM/P99xowEkD3OYCJrqLQC4k61gEQwG5dJLL5Unn3xShg0bJnfeeadMmzZNFi5cGPGY4uJiqaioMB7l5eWOGw0gedSawkSAYAG4nq1g0a1bNxkwYEDYtosvvlgOHYq8RoDP55Ps7OywB4CWw9xjESBXAK5nK1iMHDlSdu/eHbbt66+/lp49e8a0UQBSh7nGgqEQALaCxQMPPCAbNmyQJ598Uvbu3StvvPGGvPjii1JUVBSv9gFIcubhj1qCBeB6toLFFVdcIcuXL5c333xTBg0aJI8//rg899xzMmnSpHi1D0CSqzHdbhpUBAvA7Wwvm37TTTfJTTfdFI+2AEhB5qEQijcBsFYIAEfCijcJFoDrESwAOGKuq2AoBADBAoAjtfRYADAhWABwxLwIWYAeC8D1CBYAHDH3UgSYIQtwPYIFAEfMt5vSYwGAYAHAEWbeBGBGsADgSFjxJj0WgOsRLAA4Er66aTM2BEBSIFgAcMQ8+sFQCACCBQBHlOJ2UwANCBYAHDHPtskEWQAIFgAcMWcJggUAggUAR4IMhQAwIVgAcERRvAnAhGABwBFqLACYESwAOBJ2uylDIYDrESwAOEKPBQAzggUAR8LnsWjGhgBICgQLAI6YFjeVQJA5vQG3I1gAcIShEABmBAsAjoSvFdJ87QCQHAgWABxhrRAAZgQLAI4wFALAjGABwBHmsQBgRrAA4Ag9FgDMCBYAHFGsbgrAhGABwBFzmCBYACBYAHCEZdMBmBEsADhizhLkCgAECwCOmHssuCsEAMECgCMECwBmBAsAjjClNwAzggUAR8xTeit6LADXI1gAcCR85s3maweA5ECwAOAINRYAzAgWAByhxwKAGcECgCPUWAAwI1gAcIShEABmBAsAjjAUAsCMYAHAEXosAJgRLAA4wlohAMwIFgAcoccCgJmtYPHoo4+Kx+MJe/Tv3z9ebQOQAggWAMzS7R4wcOBA+eijjxreIN32WwBoQczrg1C8CcB2KkhPT5fc3Nx4tAVACmIeCwBmtmss9uzZI3l5edKnTx+ZNGmSHDp0KOr+fr9fKisrwx4AWg5uNwVgZitYFBQUyJIlS2TFihWyYMEC2b9/v1x55ZVSVVUV8ZjS0lLJyckxHvn5+Y4bDSB5UGMBwMyjHPRdnjx5Unr27Cnz5s2TqVOnWu7j9/vF7/cbzysrKyU/P18qKiokOztb96MBJInL//cj+fZUw8/4/tKfisfjacYWAYiHyspKycnJOevfb0eVl+3atZOLLrpI9u7dG3Efn88nPp/PyccASGKN/22ilAi5AnAvR/NYnDp1Svbt2yfdunWLVXsApJjGwx8MhwDuZitY/PGPf5Q1a9bIgQMHZN26dXLrrbdKWlqaTJw4MV7tA5DkGhdsUsAJuJutoZDDhw/LxIkT5bvvvpPOnTvLT37yE9mwYYN07tw5Xu0DkOTosQBgZitYLF26NF7tAJCiGucIcgXgbqwVAsAReiwAmBEsADhCsABgRrAA4AjFmwDMCBYAHGkyxx7BAnA1ggUAR5r2WJAsADcjWABwhBoLAGYECwDalFJNbi+lxgJwN4IFAG1WIcLBuoYAWgCCBQBtVsMe9FgA7kawAKDNOliQLAA3I1gA0GaVIQgWgLsRLABoM4cIj6fuv+QKwN0IFgC0mesp0r2e+m0kC8DNCBYAtJlDRJoRLJqrNQCSAcECgDYVbPg63Vv364QeC8DdCBYAtFn1WDCPBeBuBAsA2hgKAdAYwQKAtlCI8HhEvB6KNwEQLAA4EBr28Ho8Ut9hIcFglAMAtHgECwDaQj0WXnosANQjWADQFgoRHlOPBbkCcDeCBQBtQWMopC5cmLcBcCeCBQBtyhgK8Uj9NBYEC8DlCBYAtAXDije53RQAwQKAA1a3mzJBFuBuBAsA2sw9FqHVTemxANyNYAFAmzIVb3K7KQARggUAB4Lm4k2jx4JgAbgZwQKAtvB5LEI1Fs3ZIgDNjWABQFto+u5Qb4UIPRaA2xEsAGjjdlMAjREsAGhT5rVCmCALgBAsADhgXWNBsADcjGABQJsxFOI1rRXCsumAqxEsAGjjdlMAjREsAGhTFG8CaIRgAUBb+FohdV9TYwG4G8ECgLbwtULosQBAsADgQDBsrZDwbQDciWABQFvDzJseFiEDICIECwAOsFYIgMYIFgC0mYdCPAyFABCCBQAHQhkizcvtpgDqECwAaAsfCgnfBsCdHAWLOXPmiMfjkRkzZsSoOQBSSdC8CBlrhQAQB8Fi06ZNsmjRIhkyZEgs2wMghTCPBYDGtILFqVOnZNKkSfLSSy9J+/btY90mAClCMY8FgEa0gkVRUZGMGzdORo8efdZ9/X6/VFZWhj0AtAwNU3pTvAmgTrrdA5YuXSpbtmyRTZs2ndP+paWlMnv2bNsNA5D8wmberP9nCjUWgLvZ6rEoLy+X+++/X15//XXJzMw8p2OKi4uloqLCeJSXl2s1FEDyMS+bbtRY0GUBuJqtHouysjI5ceKEXHrppca2QCAga9eulb/85S/i9/slLS0t7Bifzyc+ny82rQWQVFg2HUBjtoLFqFGj5MsvvwzbNmXKFOnfv7889NBDTUIFgJatYR4LijcB1LEVLLKysmTQoEFh28477zzp2LFjk+0AWj6rRcjIFYC7MfMmAG2sFQKgMdt3hTS2evXqGDQDQCpSpuJNaiwAiNBjAcAB1goB0BjBAoA21goB0BjBAoA21goB0BjBAoA2Yx4LL7ebAqhDsACgjbVCADRGsACgLRg282bdNmosAHcjWADQZi7ebKixIFgAbkawAKDNaq2QQLA5WwSguREsAGizWitECT0WgJsRLABoMy+b7vWyVggAggUAByzXCuG2EMDVCBYAtLFWCIDGCBYAtIV6J1grBEAIwQKANtYKAdAYwQKANtYKAdAYwQKANmUq3mQoBIAIwQKAA6wVAqAxggUAbQHWCgHQCMECgLbweSxYKwQAwQKAA6EMkeZlKARAHYIFAG3MYwGgMYIFAG3W81g0Y4MANDuCBQBt4fNYhG8D4E4ECwDawuexoMYCAMECgAPh81iEtpEsADcjWADQZh4K8XpZKwQAwQKAA+bizdA8FgHGQgBXI1gA0GbUWHjNQyHN2CAAzY5gAUBbaCjE4xFJY9l0AEKwAOBAw1AIM28CqEOwAKAtfK2Q8G0A3IlgAUCboscCQCMECwDaGmosPOKt/21CjQXgbgQLANqs1gphKARwN4IFAG3ha4XUB4tgc7YIQHMjWADQFr5WSN02eiwAdyNYANAW6p3wmIo3yRWAuxEsAGgLWyuEHgsAQrAA4IDVWiEEC8DdCBYAtKmwHgvmsQBAsADggHmtkNBQCPNYAO5GsACgjbVCADRGsACgzSje9LJWCIA6toLFggULZMiQIZKdnS3Z2dlSWFgoH374YbzaBiDJsVYIgMZsBYvu3bvLnDlzpKysTDZv3izXXXed3HLLLbJjx454tQ9AEgtbK8SYx4JkAbhZup2db7755rDnTzzxhCxYsEA2bNggAwcOjGnDACS/IDNvAmjEVrAwCwQCsmzZMjl9+rQUFhbGsk0AUoS5eNPDUAgA0QgWX375pRQWFsqZM2ekbdu2snz5chkwYEDE/f1+v/j9fuN5ZWWlXksBJB3WCgHQmO27Qvr16yfbtm2TjRs3yvTp02Xy5Mny1VdfRdy/tLRUcnJyjEd+fr6jBgNIHqHeCY/HI14va4UA0AgWGRkZcsEFF8hll10mpaWlMnToUHn++ecj7l9cXCwVFRXGo7y83FGDASSPQJC1QgCE066xCAkGg2FDHY35fD7x+XxOPwZAEjIPhbBWCAARm8GiuLhYxo4dKz169JCqqip54403ZPXq1bJy5cp4tQ9AErOceTPYjA0C0OxsBYsTJ07IHXfcIUePHpWcnBwZMmSIrFy5Uq6//vp4tQ9AEmuYeZOhEAB1bAWLl19+OV7tAJCCzMumexkKASCsFQLAAfOy6Q1rhTRjgwA0O4IFAG3mZdPTvEzpDYBgAcABlk0H0BjBAoC2oGIeCwDhCBYAtClT8aYxjwVdFoCrESwAaLNeNr05WwSguREsAGhj2XQAjREsAGgLzbJJ8SaAEIIFAG3W81iQLAA3I1gA0NawbLpQYwFARAgWABwIv92UKb0BECwAOGBMkOWleBNAHYIFAG3hNRYUbwIgWABwwOp2UxHWCwHcjGABQFtD8WZDjYV5OwD3IVgA0GZVvGneDsB9CBYAtIXyg0dEPKbfJgQLwL0IFgC0BerHPNK84T0W5ArAvQgWALQZQyFeT1jxJj0WgHsRLABoC78rhOJNAAQLAA6EAkSaaa2Quu0kC8CtCBYAtIUCROPbTVWwuVoEoLkRLABoUUoZRZpNh0LosQDcimABQIu5jiKN4k0A9QgWALQETMnCY1orRITiTcDNCBYAtJh7JUK9FaxwCoBgAUCLajQUItJQZ0GwANyLYAFASyCsx6I+WHhZOh1wO4IFAC1Bq2ARGgohWQCuRbAAoMU8V0VDjUXdF4yEAO5FsACgxXIohBoLwPUIFgC0hA2F1HdZeLgrBHA9ggUALaE6CvPEWA09Fs3RIgDJgGABQIuxAJkpWYS+VPRYAK5FsACgxbwAWQg9FgAIFgC0BCyGQjwUbwKuR7AAoCWUHdI8TYdCCBaAexEsAGgJ3W7qtRgKIVcA7kWwAKAl1CvhtSjepMcCcC+CBQAtSkWrsWiOFgFIBgQLAFoC9VN6hw2F1P9GoccCcC+CBQAt1kMhoRoLggXgVgQLAFqsbjdlHgsABAsAWkKdEuahEA/LpgOuZytYlJaWyhVXXCFZWVnSpUsXGT9+vOzevTtebQOQxIJRbjclVwDuZStYrFmzRoqKimTDhg2yatUqqampkRtuuEFOnz4dr/YBSFLGPBam3yKsFQIg3c7OK1asCHu+ZMkS6dKli5SVlclVV10V04YBSG6h8JBGjwUAE1vBorGKigoREenQoUPEffx+v/j9fuN5ZWWlk48EkCSCljUWrBUCuJ128WYwGJQZM2bIyJEjZdCgQRH3Ky0tlZycHOORn5+v+5EAkkjorhBP2F0hdf8lWADupR0sioqKZPv27bJ06dKo+xUXF0tFRYXxKC8v1/1IAEkkFB7SLOexaJYmAUgCWkMh99xzj7z//vuydu1a6d69e9R9fT6f+Hw+rcYBSF5Bq5k36bEAXM9WsFBKyb333ivLly+X1atXS+/evePVLgBJzup201CNRYDqTcC1bAWLoqIieeONN+Tdd9+VrKwsOXbsmIiI5OTkSOvWrePSQADJKRjldlNyBeBetmosFixYIBUVFXLNNddIt27djMdbb70Vr/YBSFLRJshiHgvAvWwPhQCASIQaCy/zWABux1ohALQYM29yuykAE4IFAC0q6lohBAvArQgWALQYM28yjwUAE4IFAC2hW0rNQyEehkIA1yNYANASbeZNijcB9yJYANCiLBYho3gTAMECgJaGRciYxwJAA4IFAC3GUEhYjQVDIYDbESwAaLGeeTP8NQDuQ7AAoCXa7ab0WADuRbAAoCVoNfNm/W8UaiwA9yJYANASDLJsOoCmCBYAtDAUAsAKwQKAloBFj0XoDpEgyQJwLYIFAC1Wt5uGei8C1FgArkWwAKDFaubNNGosANcjWADQEuqVMM+8GVo3hKEQwL0IFgC0NCxC1rCNoRAABAsAWqxuNw0NhdBjAbgXwQKAllB2sBoKoccCcC+CBQAtVkMhRrAINkeLACQDggUALZZDIaHiTXosANciWADQErS43dTL7aaA6xEsAGixWjY9NCxCsADci2ABQEvAYnVT464QhkIA1yJYANASyg5p5kXIvAyFAG5HsACgJRQePFbzWNBjAbgWwQKAlqgzb9JjAbgWwQKAFstFyJjHAnA9ggUALQyFALBCsACgxRgK8VC8CaABwQKAlqDl7aZ1/2WtEMC9CBYAtATr6yi8XospvemxAFyLYAFAS6hXwjQSwlAIAIIFAD2hXol0L8WbABoQLABoqQ2G5rFo+DVCjwUAggUALaGhEKseiwC5AnAtggUALYFAqMeC4k0ADQgWALQ0DIUwjwWABgQLAFoC9febplkOhRAsALciWADQEqqjCKuxqP+NwlAI4F4ECwBarHosvPRYAK5HsACgpZbiTQAWCBYAtAQtbjc1ijfpsQBcy3awWLt2rdx8882Sl5cnHo9H3nnnnTg0C0CyC90V4rVYNj0QbJYmAUgCtoPF6dOnZejQoTJ//vx4tAdAigjdUpqexlAIgAbpdg8YO3asjB07Nh5tAZBCGmosTFN6U7wJuJ7tYGGX3+8Xv99vPK+srIz3RwJIAKsaC3osAMS9eLO0tFRycnKMR35+frw/EkACWNZY1P9GoccCcK+4B4vi4mKpqKgwHuXl5fH+SAAJYFVjYQyF0GMBuFbch0J8Pp/4fL54fwyABKu1mCArvb7egmABuBfzWADQUp8rjFtMRRp6L2pYNx1wLds9FqdOnZK9e/caz/fv3y/btm2TDh06SI8ePWLaOADJy7rHIjQUwkQWgFvZDhabN2+Wa6+91ng+c+ZMERGZPHmyLFmyJGYNA5DcrGos0uurN2vpsQBcy3awuOaaa0RR8Q24XuiukHSLHosaeiwA16LGAoCWgMXtpqHeC4o3AfciWADQYgyFmGbeDH1dE1D0bAIuRbAAoCU0FJKW1nQoRIReC8CtCBYAtISCg9XtpiINwQOAuxAsANimlGoIFqZeilZpDb9SCBaAOxEsANhmzgxWi5CJiNQGuDMEcCOCBQDbak23k0aqsaDHAnAnggUA28yFmeYaC4/HY4QLJskC3IlgAcC2sGBh6qUwP69hKARwJYIFANuiBYtQASe3mwLuRLAAYFu1qTciPUKPRS3TegOuRLAAYFtoWfSMdK94PI17LFg6HXAzggUA22pq63ojMtKa/goJTevNUAjgTgQLALaFCjNbpXmavEbxJuBuBAsAtlUbwaLpr5BQ2GAeC8CdCBYAbAvVT1gFizTmsQBcjWABwLbQMEdGulWPRd027goB3IlgAcC2UPGmVY1FOkMhgKsRLADYFq3GIq3+rhCGQgB3IlgAsC1ajUUro8aCoRDAjQgWAGyLVmMR2lZNsABciWABwLbqKBNk+eqDhb+WYAG4EcECgG3VUSbI8qWniQjBAnArggUA22qiFG/6WtX3WNQEEtomAMmBYAHANuN2U4saC4ZCAHcjWACwzVjd1LLGgqEQwM0IFgBsi15jEeqxYCgEcCOCBQDbzq3Ggh4LwI0IFgBsq66NEiwYCgFcjWABwLYf6+/4aJOR1uQ1hkIAdyNYALDtx+pzCRb0WABuRLAAYNvp+mDROiO9yWu+VvVDIdRYAK5EsABg24/VtSLCUAiApggWAGz7IepQCMWbgJsRLADY1hAsmg6FZNbfbhqqwwDgLgQLALZFK97MymwlIiKn/LUJbROA5ECwAGDb6foai9YWwSK7dV0vRuWPNQltE4DkQLAAYNu59FhUnqkRpVRC2wWg+REsANhm1Fi0alpjkZ1Zt60moCjgBFyIYAHAljM1AWPmzZw2rZq8fl5Gunjq1yZjOARwH4IFAFu+PeUXkbol00O9E2Zer0eyfPV1Fmco4ATchmABwJZvT1WLiEinthni8TRdNl2koc6igh4LwHUIFgBs+baqrseiU5Yv4j65OZkiInK04seEtAlA8tAKFvPnz5devXpJZmamFBQUyOeffx7rdgFIUqGhkE5tIweLHh3aiIhI+fcEC8BtbAeLt956S2bOnCklJSWyZcsWGTp0qIwZM0ZOnDgRj/YBSDIHvvtBRETOb9c64j757eteO/T9DwlpE4DkYTtYzJs3T6ZNmyZTpkyRAQMGyMKFC6VNmzbyyiuvxKN9AJLMv8pPiohIv9ysiPv07dJWRES2HvpvIpoEIIk0LemOorq6WsrKyqS4uNjY5vV6ZfTo0bJ+/XrLY/x+v/j9fuN5ZWWlZlOjm/f/dse8At3O5D52pgGyM2eQsvHO9t7Xxr625jiKU3tb8PfMTnvjtOs5/79+piYo6//9nYiI/OSCThH3u+rCzpLm9ciuY1VS9MYW6Rxl2ERHhJpRAPVmXn+RUUSdaLaCxbfffiuBQEC6du0atr1r166ya9cuy2NKS0tl9uzZ+i08R0s3lcuJKv/ZdwTg2G2X50uvTudFfL39eRny2xG95OVP98s/vjiawJYBEBGZfk3f1AgWOoqLi2XmzJnG88rKSsnPz4/55/x2ZC/5wX/uqyna/RePrd1tvrmdve23+9wPiOf3xPZ7x/GfpHbe2s73z/5725Ms7e7evrXcMCD3rPv933EXy//p01G+Pl4V05VObfXwAC5ltfJwotj65E6dOklaWpocP348bPvx48clN9f6F43P5xOfL7bdoFb+cM0Fcf8MAOfO4/HI9QO6yvUDup59ZwAthq3izYyMDLnsssvk448/NrYFg0H5+OOPpbCwMOaNAwAAqcV2X8nMmTNl8uTJcvnll8vw4cPlueeek9OnT8uUKVPi0T4AAJBCbAeL2267Tf7zn//II488IseOHZNLLrlEVqxY0aSgEwAAuI9H2bmnMgYqKyslJydHKioqJDs7O5EfDQAANJ3r32/WCgEAADFDsAAAADFDsAAAADFDsAAAADFDsAAAADFDsAAAADFDsAAAADFDsAAAADFDsAAAADGT8HVVQxN9VlZWJvqjAQCAptDf7bNN2J3wYFFVVSUiIvn5+Yn+aAAA4FBVVZXk5OREfD3ha4UEg0E5cuSIZGVlicfjidn7VlZWSn5+vpSXl7fYNUha+jlyfqmvpZ8j55f6Wvo5xvP8lFJSVVUleXl54vVGrqRIeI+F1+uV7t27x+39s7OzW+T/LGYt/Rw5v9TX0s+R80t9Lf0c43V+0XoqQijeBAAAMUOwAAAAMdNigoXP55OSkhLx+XzN3ZS4aennyPmlvpZ+jpxf6mvp55gM55fw4k0AANBytZgeCwAA0PwIFgAAIGYIFgAAIGYIFgAAIGZSJlg88cQTMmLECGnTpo20a9fOcp9Dhw7JuHHjpE2bNtKlSxd58MEHpba2Nur7fv/99zJp0iTJzs6Wdu3aydSpU+XUqVNxOAN7Vq9eLR6Px/KxadOmiMddc801Tfa/++67E9hye3r16tWkvXPmzIl6zJkzZ6SoqEg6duwobdu2lV/84hdy/PjxBLX43B04cECmTp0qvXv3ltatW0vfvn2lpKREqqurox6X7Ndw/vz50qtXL8nMzJSCggL5/PPPo+6/bNky6d+/v2RmZsrgwYPlgw8+SFBL7SktLZUrrrhCsrKypEuXLjJ+/HjZvXt31GOWLFnS5FplZmYmqMX2Pfroo03a279//6jHpMr1E7H+feLxeKSoqMhy/2S/fmvXrpWbb75Z8vLyxOPxyDvvvBP2ulJKHnnkEenWrZu0bt1aRo8eLXv27Dnr+9r9GbYrZYJFdXW1TJgwQaZPn275eiAQkHHjxkl1dbWsW7dOXn31VVmyZIk88sgjUd930qRJsmPHDlm1apW8//77snbtWrnzzjvjcQq2jBgxQo4ePRr2+P3vfy+9e/eWyy+/POqx06ZNCzvu6aefTlCr9Tz22GNh7b333nuj7v/AAw/I3//+d1m2bJmsWbNGjhw5Ij//+c8T1Npzt2vXLgkGg7Jo0SLZsWOHPPvss7Jw4UL505/+dNZjk/UavvXWWzJz5kwpKSmRLVu2yNChQ2XMmDFy4sQJy/3XrVsnEydOlKlTp8rWrVtl/PjxMn78eNm+fXuCW352a9askaKiItmwYYOsWrVKampq5IYbbpDTp09HPS47OzvsWh08eDBBLdYzcODAsPZ++umnEfdNpesnIrJp06awc1u1apWIiEyYMCHiMcl8/U6fPi1Dhw6V+fPnW77+9NNPy5///GdZuHChbNy4Uc477zwZM2aMnDlzJuJ72v0Z1qJSzOLFi1VOTk6T7R988IHyer3q2LFjxrYFCxao7Oxs5ff7Ld/rq6++UiKiNm3aZGz78MMPlcfjUd98803M2+5EdXW16ty5s3rsscei7nf11Ver+++/PzGNioGePXuqZ5999pz3P3nypGrVqpVatmyZsW3nzp1KRNT69evj0MLYevrpp1Xv3r2j7pPM13D48OGqqKjIeB4IBFReXp4qLS213P+Xv/ylGjduXNi2goICddddd8W1nbFw4sQJJSJqzZo1EfeJ9PsoWZWUlKihQ4ee8/6pfP2UUur+++9Xffv2VcFg0PL1VLp+IqKWL19uPA8Ggyo3N1c988wzxraTJ08qn8+n3nzzzYjvY/dnWEfK9Ficzfr162Xw4MHStWtXY9uYMWOksrJSduzYEfGYdu3ahfUAjB49Wrxer2zcuDHubbbjvffek++++06mTJly1n1ff/116dSpkwwaNEiKi4vlhx9+SEAL9c2ZM0c6duwow4YNk2eeeSbq8FVZWZnU1NTI6NGjjW39+/eXHj16yPr16xPRXEcqKiqkQ4cOZ90vGa9hdXW1lJWVhX3vvV6vjB49OuL3fv369WH7i9T9XKbKtRKRs16vU6dOSc+ePSU/P19uueWWiL9vksWePXskLy9P+vTpI5MmTZJDhw5F3DeVr191dbW89tpr8rvf/S7qgpepdv1C9u/fL8eOHQu7Pjk5OVJQUBDx+uj8DOtI+CJk8XLs2LGwUCEixvNjx45FPKZLly5h29LT06VDhw4Rj2kuL7/8sowZM+asC7j96le/kp49e0peXp588cUX8tBDD8nu3bvlb3/7W4Jaas99990nl156qXTo0EHWrVsnxcXFcvToUZk3b57l/seOHZOMjIwmdTZdu3ZNumvW2N69e+WFF16QuXPnRt0vWa/ht99+K4FAwPLnbNeuXZbHRPq5TPZrFQwGZcaMGTJy5EgZNGhQxP369esnr7zyigwZMkQqKipk7ty5MmLECNmxY0dcF1vUVVBQIEuWLJF+/frJ0aNHZfbs2XLllVfK9u3bJSsrq8n+qXr9RETeeecdOXnypPz2t7+NuE+qXT+z0DWwc310foZ1NGuwePjhh+Wpp56Kus/OnTvPWlyUSnTO+fDhw7Jy5Up5++23z/r+5vqQwYMHS7du3WTUqFGyb98+6du3r37DbbBzjjNnzjS2DRkyRDIyMuSuu+6S0tLSpJ1yV+cafvPNN3LjjTfKhAkTZNq0aVGPTYZr6HZFRUWyffv2qPUHIiKFhYVSWFhoPB8xYoRcfPHFsmjRInn88cfj3Uzbxo4da3w9ZMgQKSgokJ49e8rbb78tU6dObcaWxd7LL78sY8eOlby8vIj7pNr1SxXNGixmzZoVNU2KiPTp0+ec3is3N7dJZWvoToHc3NyIxzQuWKmtrZXvv/8+4jFO6Zzz4sWLpWPHjvKzn/3M9ucVFBSISN2/lhP1R8nJdS0oKJDa2lo5cOCA9OvXr8nrubm5Ul1dLSdPngzrtTh+/Hjcrlljds/vyJEjcu2118qIESPkxRdftP15zXENrXTq1EnS0tKa3IET7Xufm5tra/9kcM899xiF3Hb/1dqqVSsZNmyY7N27N06ti6127drJRRddFLG9qXj9REQOHjwoH330ke1evlS6fqFrcPz4cenWrZux/fjx43LJJZdYHqPzM6wlZtUaCXK24s3jx48b2xYtWqSys7PVmTNnLN8rVLy5efNmY9vKlSuTqngzGAyq3r17q1mzZmkd/+mnnyoRUf/6179i3LL4eO2115TX61Xff/+95euh4s2//vWvxrZdu3YlbfHm4cOH1YUXXqhuv/12VVtbq/UeyXQNhw8fru655x7jeSAQUOeff37U4s2bbropbFthYWFSFv8Fg0FVVFSk8vLy1Ndff631HrW1tapfv37qgQceiHHr4qOqqkq1b99ePf/885avp9L1MyspKVG5ubmqpqbG1nHJfP0kQvHm3LlzjW0VFRXnVLxp52dYq60xe6c4O3jwoNq6dauaPXu2atu2rdq6davaunWrqqqqUkrV/Q8xaNAgdcMNN6ht27apFStWqM6dO6vi4mLjPTZu3Kj69eunDh8+bGy78cYb1bBhw9TGjRvVp59+qi688EI1ceLEhJ9fJB999JESEbVz584mrx0+fFj169dPbdy4USml1N69e9Vjjz2mNm/erPbv36/effdd1adPH3XVVVclutnnZN26derZZ59V27ZtU/v27VOvvfaa6ty5s7rjjjuMfRqfo1JK3X333apHjx7qn//8p9q8ebMqLCxUhYWFzXEKUR0+fFhdcMEFatSoUerw4cPq6NGjxsO8Typdw6VLlyqfz6eWLFmivvrqK3XnnXeqdu3aGXdj/eY3v1EPP/ywsf9nn32m0tPT1dy5c9XOnTtVSUmJatWqlfryyy+b6xQimj59usrJyVGrV68Ou1Y//PCDsU/j85s9e7ZauXKl2rdvnyorK1O33367yszMVDt27GiOUzirWbNmqdWrV6v9+/erzz77TI0ePVp16tRJnThxQimV2tcvJBAIqB49eqiHHnqoyWupdv2qqqqMv3UioubNm6e2bt2qDh48qJRSas6cOapdu3bq3XffVV988YW65ZZbVO/evdWPP/5ovMd1112nXnjhBeP52X6GYyFlgsXkyZOViDR5fPLJJ8Y+Bw4cUGPHjlWtW7dWnTp1UrNmzQpLrJ988okSEbV//35j23fffacmTpyo2rZtq7Kzs9WUKVOMsJIMJk6cqEaMGGH52v79+8O+B4cOHVJXXXWV6tChg/L5fOqCCy5QDz74oKqoqEhgi89dWVmZKigoUDk5OSozM1NdfPHF6sknnwzrYWp8jkop9eOPP6o//OEPqn379qpNmzbq1ltvDftjnSwWL15s+f+suaMwFa/hCy+8oHr06KEyMjLU8OHD1YYNG4zXrr76ajV58uSw/d9++2110UUXqYyMDDVw4ED1j3/8I8EtPjeRrtXixYuNfRqf34wZM4zvRdeuXdVPf/pTtWXLlsQ3/hzddtttqlu3biojI0Odf/756rbbblN79+41Xk/l6xeycuVKJSJq9+7dTV5LtesX+pvV+BE6h2AwqP7nf/5Hde3aVfl8PjVq1Kgm592zZ09VUlISti3az3AssGw6AACImRYzjwUAAGh+BAsAABAzBAsAABAzBAsAABAzBAsAABAzBAsAABAzBAsAABAzBAsAABAzBAsAABAzBAsAABAzBAsAABAzBAsAABAz/x8NRUJgVIzIQQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal_dist = lambda x, mean, var: np.exp(- np.square(x - mean) / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
    "\n",
    "def plot_normal_dist(mean, var, rmin=-10, rmax=10):\n",
    "    x = np.arange(rmin, rmax, 0.01)\n",
    "    y = normal_dist(x, mean, var)\n",
    "    fig = plt.plot(x, y)\n",
    "    \n",
    "# plain distribution\n",
    "lr = LR(n_features)\n",
    "data = lr.lr(x_test)\n",
    "mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "plot_normal_dist(mean, var)\n",
    "print(\"Distribution on plain data:\")\n",
    "plt.show()\n",
    "\n",
    "# encrypted distribution\n",
    "def encrypted_out_distribution(eelr, enc_x_test):\n",
    "    w = eelr.weight\n",
    "    b = eelr.bias\n",
    "    data = []\n",
    "    for enc_x in enc_x_test:\n",
    "        enc_out = enc_x.dot(w) + b\n",
    "        data.append(enc_out.decrypt())\n",
    "    data = torch.tensor(data)\n",
    "    mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "    plot_normal_dist(mean, var)\n",
    "    print(\"Distribution on encrypted data:\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data falls into $[-5,5]$, the sigmoid approximation should be good enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally reached the last part, which is about training an encrypted logistic regression model on encrypted data! You can see that we decrypt the weights and re-encrypt them again after every epoch, this is necessary since after updating the weights at the end of the epoch, we can no longer use them to perform enough multiplications, so we need to get them back to the initial ciphertext level. In a real scenario, this would translate to sending the weights back to the secret-key holder for decryption and re-encryption. In that case, it will result in just a few Kilobytes of communication per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 25/25 [6:05:40<00:00, 877.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_time :  877.4709065055847\n",
      "====================\n",
      "LR_mem mean :  328.6196875\n",
      "LR_mem sum :  8215.4921875\n",
      "LR_mem max :  366.6875    LR_mem min :  232.0078125\n",
      "LR_mem :  [366.6875, 353.53515625, 337.43359375, 336.13671875, 333.62890625, 331.17578125, 334.2890625, 332.54296875, 232.0078125, 332.47265625, 327.73828125, 330.515625, 329.7109375, 329.98828125, 329.69140625, 328.65234375, 329.0234375, 328.06640625, 329.08203125, 328.6015625, 330.0078125, 327.7890625, 325.59375, 326.95703125, 324.1640625]\n",
      "====================\n",
      "LR_mem_sub :  6571.27484375\n",
      "LR_mem_first :  6194.8125\n",
      "LR_mem_last :  6579.91796875\n",
      "LR_mem_sub :  [6552.5625, 6573.39453125, 6576.85546875, 6576.109375, 6574.5078125, 6574.40625, 6577.35546875, 6574.3203125, 6474.37109375, 6575.14453125, 6572.65625, 6576.71484375, 6576.91796875, 6575.46875, 6575.2578125, 6576.890625, 6576.34375, 6575.59765625, 6577.3359375, 6576.203125, 6578.20703125, 6578.16796875, 6578.8203125, 6578.34375, 6579.91796875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_list = []\n",
    "\n",
    "LR_time = []\n",
    "LR_mem = []\n",
    "LR_mem_sub = []\n",
    "\n",
    "sfm_s = memory_usage()\n",
    "\n",
    "for iter in tqdm(range(25)):\n",
    "    # eelr = EncryptedLR(lr)\n",
    "    # eelr.encrypt(ctx_training)\n",
    "    # # encrypted_out_distribution(eelr, enc_x_train)\n",
    "    mem_buff = {}\n",
    "    mem_flag[0] = True\n",
    "    st = time()\n",
    "    t = threading.Thread(target = record_mem)\n",
    "    t.start()\n",
    "\n",
    "    \n",
    "    eelr = EncryptedLR(LR(n_features))\n",
    "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "    # print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
    "    \n",
    "    times = []\n",
    "    accuracy_list = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        eelr.encrypt(ctx_training)\n",
    "        \n",
    "        # if you want to keep an eye on the distribution to make sure\n",
    "        # the function approximation is still working fine\n",
    "        # WARNING: this operation is time consuming\n",
    "        # encrypted_out_distribution(eelr, enc_x_train)\n",
    "        \n",
    "        t_start = time()\n",
    "        for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
    "            enc_out = eelr.forward(enc_x)\n",
    "            eelr.backward(enc_x, enc_out, enc_y)\n",
    "        eelr.update_parameters()\n",
    "        t_end = time()\n",
    "        times.append(t_end - t_start)\n",
    "        \n",
    "        eelr.decrypt()\n",
    "        accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "    main_list.append(accuracy_list)\n",
    "\n",
    "    et = time()\n",
    "    mem_flag[0] = False\n",
    "    t.join()\n",
    "    \n",
    "    ft = et-st\n",
    "    fm = mem_buff[max(mem_buff)]-mem_buff[min(mem_buff)]\n",
    "\n",
    "    fm_s = memory_usage()\n",
    "    LR_time.append(ft)\n",
    "    LR_mem.append(fm)\n",
    "    LR_mem_sub.append(fm_s)\n",
    "\n",
    "print(\"LR_time : \", np.mean(LR_time))\n",
    "print(\"====================\")\n",
    "print(\"LR_mem mean : \", np.mean(LR_mem))\n",
    "print(\"LR_mem sum : \", np.sum(LR_mem))\n",
    "print(\"LR_mem max : \", max(LR_mem), \"   LR_mem min : \", min(LR_mem))\n",
    "print(\"LR_mem : \", LR_mem)\n",
    "\n",
    "print(\"====================\")\n",
    "print(\"LR_mem_sub : \", np.mean(LR_mem_sub))\n",
    "print(\"LR_mem_first : \", sfm_s )\n",
    "print(\"LR_mem_last : \", LR_mem_sub[-1])\n",
    "print(\"LR_mem_sub : \", LR_mem_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after running this cell many times myself, I always feel the joy when I see it working on encrypted data, so I hope you are feeling this joy as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.6224), tensor(1.), tensor(0.8050), tensor(0.9502), tensor(0.6805)]\n",
      "[tensor(0.6349), tensor(0.5187), tensor(0.6058), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6390), tensor(0.5892), tensor(0.6100), tensor(0.6058), tensor(0.4813)]\n",
      "[tensor(0.7095), tensor(0.5187), tensor(0.6058), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6224), tensor(0.5187), tensor(0.6058), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6390), tensor(0.5643), tensor(0.6100), tensor(0.5934), tensor(0.4813)]\n",
      "[tensor(0.6390), tensor(0.5187), tensor(0.6100), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6307), tensor(0.5643), tensor(0.6100), tensor(0.6017), tensor(0.4813)]\n",
      "[tensor(0.6224), tensor(0.7552), tensor(0.6141), tensor(0.6224), tensor(0.4813)]\n",
      "[tensor(0.6390), tensor(0.5187), tensor(0.6100), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6390), tensor(0.5187), tensor(0.6100), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6266), tensor(0.5187), tensor(0.6058), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6349), tensor(0.6805), tensor(0.6100), tensor(0.6100), tensor(0.4813)]\n",
      "[tensor(0.6349), tensor(0.5187), tensor(0.6100), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6224), tensor(0.8631), tensor(0.6183), tensor(0.7344), tensor(0.4896)]\n",
      "[tensor(0.6224), tensor(0.7718), tensor(0.6183), tensor(0.6224), tensor(0.4813)]\n",
      "[tensor(0.6349), tensor(0.5643), tensor(0.6100), tensor(0.5975), tensor(0.4813)]\n",
      "[tensor(0.6307), tensor(0.6929), tensor(0.6141), tensor(0.6183), tensor(0.4813)]\n",
      "[tensor(0.6390), tensor(0.5643), tensor(0.6100), tensor(0.5975), tensor(0.4813)]\n",
      "[tensor(0.6224), tensor(0.8672), tensor(0.6183), tensor(0.7344), tensor(0.4896)]\n",
      "[tensor(0.6390), tensor(0.5187), tensor(0.6017), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6432), tensor(0.5187), tensor(0.6017), tensor(0.5145), tensor(0.4813)]\n",
      "[tensor(0.6349), tensor(0.5187), tensor(0.6100), tensor(0.5519), tensor(0.4813)]\n",
      "[tensor(0.6224), tensor(0.5851), tensor(0.6100), tensor(0.6058), tensor(0.4813)]\n",
      "[tensor(0.6266), tensor(0.5768), tensor(0.6100), tensor(0.5934), tensor(0.4813)]\n"
     ]
    }
   ],
   "source": [
    "for i in main_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  125\n",
      "1 :  116\n"
     ]
    }
   ],
   "source": [
    "one = 0\n",
    "zero = 0\n",
    "for i in y_test:\n",
    "    if 1 == i[0]:\n",
    "        one += 1\n",
    "    elif 0 == i[0]:\n",
    "        zero += 1\n",
    "\n",
    "print(\"0 : \", zero)\n",
    "print(\"1 : \", one)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for i in range(len(main_list[0])):\n",
    "    tmp = []\n",
    "    for j in range(len(main_list)):\n",
    "        tmp.append(main_list[j][i])\n",
    "    final.append(np.mean(tmp))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6348548, 0.61377597, 0.61775935, 0.59136933, 0.4899585]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.55850625, 0.52315354, 0.48132783, 0.48132783, 0.506722]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.6348548, 0.61377597, 0.61775935, 0.59136933, 0.4899585]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
