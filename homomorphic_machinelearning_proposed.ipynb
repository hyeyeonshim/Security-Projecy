{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Training and Evaluation of Logistic Regression on Encrypted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "from time import sleep\n",
    "\n",
    "# those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import psutil\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.random.manual_seed(10)\n",
    "random.seed(10)\n",
    "np.random.seed(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cic_dataset():\n",
    "    save_list = [\"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
    "    \n",
    "    for i in save_list:\n",
    "        save_path = 'data/' + i+'.csv'\n",
    "        globals()[\"{}\".format(i)] = pd.read_csv(save_path)\n",
    "    \n",
    "    x_tra = torch.tensor(X_train.values).float()\n",
    "    y_tra = torch.tensor(y_train.values).float()\n",
    "    x_te = torch.tensor(X_test.values).float()\n",
    "    y_te = torch.tensor(y_test.values).float()\n",
    "    \n",
    "    print(\"############# Data summary #############\")\n",
    "    print(f\"x_train has shape: {x_tra.shape}\")\n",
    "    print(f\"y_train has shape: {y_tra.shape}\")\n",
    "    print(f\"x_test has shape: {x_te.shape}\")\n",
    "    print(f\"y_test has shape: {y_te.shape}\")\n",
    "    print(\"#######################################\")\n",
    "    return x_tra, y_tra, x_te, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset():\n",
    "    save_path = 'data/test_clear3.csv'\n",
    "    data = pd.read_csv(save_path)\n",
    "    print(data.shape)\n",
    "    \n",
    "    y = data['Label']\n",
    "    X = data[:]\n",
    "    X = X.drop(labels='Label',axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        shuffle=True, random_state=34)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "    scaler.fit(X_train)\n",
    "    transformed_X_train = scaler.transform(X_train)\n",
    "    transformed_X_test = scaler.transform(X_test) \n",
    "    \n",
    "    x_train = torch.tensor(transformed_X_train).float()\n",
    "    y_train = torch.tensor(y_train.values).float()\n",
    "    x_test = torch.tensor(transformed_X_test).float()\n",
    "    y_test = torch.tensor(y_test.values).float()\n",
    "    \n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    \n",
    "    print(\"############# Data summary #############\")\n",
    "    print(f\"x_train has shape: {x_train.shape}\")\n",
    "    print(f\"y_train has shape: {y_train.shape}\")\n",
    "    print(f\"x_test has shape: {x_test.shape}\")\n",
    "    print(f\"y_test has shape: {y_test.shape}\")\n",
    "    print(\"#######################################\")\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([961, 291])\n",
      "y_train has shape: torch.Size([961, 1])\n",
      "x_test has shape: torch.Size([241, 291])\n",
      "y_test has shape: torch.Size([241, 1])\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "# select dataset\n",
    "x_train, y_train, x_test, y_test = cic_dataset()\n",
    "# x_train, y_train, x_test, y_test = test_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "mem_buff = {}\n",
    "mem_flag = [True]\n",
    "\n",
    "def record_mem():    \n",
    "    global mem_buff, st\n",
    "    while mem_flag[0]:\n",
    "        p = psutil.Process()\n",
    "        rss = p.memory_info().rss/2**20        \n",
    "        mem_buff[time()-st] = (rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usage(message: str = 'debug'):\n",
    "    # current process RAM usage\n",
    "    p2 = psutil.Process()\n",
    "    rss = p2.memory_info().rss / 2 ** 20 # Bytes to MB\n",
    "    # print(f\"[{message}] memory usage: {rss: 10.5f} MB\")\n",
    "    return rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## partial feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index\n",
    "pinx = [0, 1, 2, 3]\n",
    "ninx = []\n",
    "for i in range(len(x_test[1])):\n",
    "    if i not in pinx:  \n",
    "        ninx.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model\n",
    "\n",
    "We will start by training a logistic regression model (without any encryption), which can be viewed as a single layer neural network with a single node. We will be using this model as a means of comparison against encrypted training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = LR(n_features)\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_time :  0.06487276554107665\n",
      "====================\n",
      "LR_mem mean :  0.358984375\n",
      "LR_mem sum :  3.58984375\n",
      "LR_mem max :  3.58984375    LR_mem min :  0.0\n",
      "LR_mem :  [3.58984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "====================\n",
      "LR_mem_sub :  511.13671875\n",
      "LR_mem_first :  507.34765625\n",
      "LR_mem_last :  511.16796875\n",
      "LR_mem_sub :  [510.9375, 511.12890625, 511.15625, 511.15625, 511.15625, 511.1640625, 511.1640625, 511.16796875, 511.16796875, 511.16796875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define the number of epochs for both plain and encrypted training\n",
    "EPOCHS = 5\n",
    "\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        # print(y.shape)\n",
    "        # print(out.shape)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # print(f\"Loss at epoch {e}: {loss.data}\")\n",
    "    return model\n",
    "\n",
    "LR_time = []\n",
    "LR_mem = []\n",
    "LR_mem_sub = []\n",
    "\n",
    "sfm_s = memory_usage()\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    mem_buff = {}\n",
    "    mem_flag[0] = True\n",
    "    st = time()\n",
    "    t = threading.Thread(target = record_mem)\n",
    "    t.start()\n",
    "    \n",
    "    \n",
    "    sleep(0.0001)\n",
    "    model = train(model, optim, criterion, x_train, y_train)\n",
    "    sleep(0.0001)\n",
    "    \n",
    "    \n",
    "    et = time()\n",
    "    mem_flag[0] = False\n",
    "    t.join()\n",
    "    ft = et-st\n",
    "    fm = mem_buff[max(mem_buff)]-mem_buff[min(mem_buff)]\n",
    "    # print(\"time : \", et-st)\n",
    "    # print(\"memory : \", mem_buff[max(mem_buff)]-mem_buff[min(mem_buff)])\n",
    "    fm_s = memory_usage()\n",
    "    LR_time.append(ft)\n",
    "    LR_mem.append(fm)\n",
    "    LR_mem_sub.append(fm_s)\n",
    "# plt.title(\"Memory Tracing\")\n",
    "# plt.ylabel(\"Memory_usage\")\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.plot(mem_buff.keys(), [mem_buff[i] for i in mem_buff.keys()])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "print(\"LR_time : \", np.mean(LR_time))\n",
    "print(\"====================\")\n",
    "print(\"LR_mem mean : \", np.mean(LR_mem))\n",
    "print(\"LR_mem sum : \", np.sum(LR_mem))\n",
    "print(\"LR_mem max : \", max(LR_mem), \"   LR_mem min : \", min(LR_mem))\n",
    "print(\"LR_mem : \", LR_mem)\n",
    "\n",
    "print(\"====================\")\n",
    "print(\"LR_mem_sub : \", np.mean(LR_mem_sub))\n",
    "print(\"LR_mem_first : \", sfm_s )\n",
    "print(\"LR_mem_last : \", LR_mem_sub[-1])\n",
    "print(\"LR_mem_sub : \", LR_mem_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on plain test_set: 1.0\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an Encrypted Logistic Regression Model on Encrypted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### privacy feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_x_train = torch.tensor(np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pinx:\n",
    "    if len(pinx) == 1:\n",
    "        enc_x_train = x_train[: ,i].reshape(-1, 1)\n",
    "    else:\n",
    "        enc_x_train = torch.cat([enc_x_train, x_train[: ,i].reshape(-1, 1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = torch.tensor(np.array([]))\n",
    "for i in ninx:\n",
    "    if len(ninx) == 1:\n",
    "        x_train2 = x_train[: ,i].reshape(-1, 1)\n",
    "    else:\n",
    "        x_train2 = torch.cat([x_train2, x_train[: ,i].reshape(-1, 1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_x_train shape :  torch.Size([961, 4])\n",
      "x_train2 shape :  torch.Size([961, 287])\n"
     ]
    }
   ],
   "source": [
    "print(\"enc_x_train shape : \", enc_x_train.shape)\n",
    "print(\"x_train2 shape : \", x_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enc training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    def __init__(self, torch_lr, pinx, nidx):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "\n",
    "        tmp = []\n",
    "        for i in pinx:\n",
    "            tmp.append(self.weight[i])\n",
    "        self.w1 = tmp\n",
    "        \n",
    "        tmp = []  \n",
    "        for i in ninx:\n",
    "            tmp.append(self.weight[i])\n",
    "        self.w2 = torch.tensor(np.array(tmp))\n",
    "    \n",
    "        self._delta_w1 = 0\n",
    "        self._delta_w2 = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        self.flow = []\n",
    "        \n",
    "    def forward(self, enc_x, x):\n",
    "        self.flow.append(\"forward\")\n",
    "        tmp1 = enc_x.dot(self.w1)\n",
    "        tmp2 = int(x.dot(self.w2))\n",
    "        enc_out = tmp1 + tmp2 + self.bias\n",
    "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def backward(self, enc_x, x, enc_out, enc_y):\n",
    "        self.flow.append(\"backward\")\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        self._delta_w1 += enc_x * out_minus_y\n",
    "        out_minus_y = out_minus_y.decrypt()[0]\n",
    "        self._delta_w2 += x * out_minus_y\n",
    "        self._delta_b += out_minus_y\n",
    "        self._count += 1\n",
    "        \n",
    "    def update_parameters(self):\n",
    "        self.flow.append(\"update_parameters\")\n",
    "        if self._count == 0:\n",
    "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
    "        # update weights\n",
    "        # We use a small regularization term to keep the output\n",
    "        # of the linear layer in the range of the sigmoid approximation\n",
    "        self.w1 -= self._delta_w1 * (1 / self._count) + self.w1 * 0.05\n",
    "        self.w2 -= self._delta_w2 * (1 / self._count) + self.w2 * 0.05\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # reset gradient accumulators and iterations count\n",
    "        self._delta_w1 = 0\n",
    "        self._delta_w2 = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        # print(\"weight : \", self.weight.decrypt() , \"bias : \", self.bias.decrypt())\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # We use the polynomial approximation of degree 3\n",
    "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
    "        # from https://eprint.iacr.org/2018/462.pdf\n",
    "        # which fits the function pretty well in the range [-5,5]\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "    \n",
    "    def plain_accuracy(self, x_test, y_test):\n",
    "        # evaluate accuracy of the model on\n",
    "        # the plain (x_test, y_test) dataset\n",
    "        w = torch.tensor(self.weight)\n",
    "        b = torch.tensor(self.bias)\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        # print(out)\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "\n",
    "    def plain_accuracy2(self, x_test, y_test, weight_cat):\n",
    "        self.flow.append(\"plain_accuracy2\")\n",
    "        # evaluate accuracy of the model on\n",
    "        # the plain (x_test, y_test) dataset\n",
    "        w = torch.tensor(weight_cat)\n",
    "        b = torch.tensor(self.bias)\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        # print(out)\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "        \n",
    "    def encrypt(self, context):\n",
    "        self.flow.append(\"encrypt\")\n",
    "        self.w1 = ts.ckks_vector(context, self.w1)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self):\n",
    "        self.flow.append(\"decrypt\")\n",
    "        self.w1 = self.w1.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "\n",
    "    def cat_weight(self):\n",
    "        self.flow.append(\"cat_weight\")\n",
    "        weight_cat = self.w1 + self.w2.tolist()\n",
    "        return weight_cat\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [24:18<00:00, 14.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_time :  14.566640419960022\n",
      "====================\n",
      "LR_mem mean :  1714.50390625\n",
      "LR_mem sum :  171450.390625\n",
      "LR_mem max :  1714.50390625    LR_mem min :  1714.50390625\n",
      "LR_mem :  [1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625, 1714.50390625]\n",
      "====================\n",
      "LR_mem_sub :  3434.6715234375\n",
      "LR_mem_first :  886.3359375\n",
      "LR_mem_last :  3443.0859375\n",
      "LR_mem_sub :  [2601.64453125, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375, 3443.0859375]\n"
     ]
    }
   ],
   "source": [
    "mem_buff = {}\n",
    "mem_flag[0] = True\n",
    "\n",
    "LR_time = []\n",
    "LR_mem = []\n",
    "LR_mem_sub = []\n",
    "\n",
    "sfm_s = memory_usage()\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    st = time()\n",
    "    t = threading.Thread(target = record_mem)\n",
    "    t.start()\n",
    "    \n",
    "    enc_x_train11 = [ts.ckks_vector(ctx_training, x.tolist()) for x in enc_x_train]\n",
    "    enc_y_train11 = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
    "    \n",
    "    et = time()\n",
    "    mem_flag[0] = False\n",
    "    t.join()\n",
    "\n",
    "    ft = et-st\n",
    "    fm = mem_buff[max(mem_buff)]-mem_buff[min(mem_buff)]\n",
    "    fm_s = memory_usage()\n",
    "    LR_time.append(ft)\n",
    "    LR_mem.append(fm)\n",
    "    LR_mem_sub.append(fm_s)\n",
    "\n",
    "\n",
    "print(\"LR_time : \", np.mean(LR_time))\n",
    "print(\"====================\")\n",
    "print(\"LR_mem mean : \", np.mean(LR_mem))\n",
    "print(\"LR_mem sum : \", np.sum(LR_mem))\n",
    "print(\"LR_mem max : \", max(LR_mem), \"   LR_mem min : \", min(LR_mem))\n",
    "print(\"LR_mem : \", LR_mem)\n",
    "\n",
    "print(\"====================\")\n",
    "print(\"LR_mem_sub : \", np.mean(LR_mem_sub))\n",
    "print(\"LR_mem_first : \", sfm_s )\n",
    "print(\"LR_mem_last : \", LR_mem_sub[-1])\n",
    "print(\"LR_mem_sub : \", LR_mem_sub)\n",
    "\n",
    "\n",
    "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in enc_x_train]\n",
    "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution on plain data:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal_dist = lambda x, mean, var: np.exp(- np.square(x - mean) / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
    "\n",
    "def plot_normal_dist(mean, var, rmin=-10, rmax=10):\n",
    "    x = np.arange(rmin, rmax, 0.01)\n",
    "    y = normal_dist(x, mean, var)\n",
    "    fig = plt.plot(x, y)\n",
    "    \n",
    "# plain distribution\n",
    "lr = LR(n_features)\n",
    "data = lr.lr(x_test)\n",
    "mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "plot_normal_dist(mean, var)\n",
    "print(\"Distribution on plain data:\")\n",
    "plt.show()\n",
    "\n",
    "# encrypted distribution\n",
    "def encrypted_out_distribution(eelr, enc_x_test):\n",
    "    w = eelr.weight\n",
    "    b = eelr.bias\n",
    "    data = []\n",
    "    for enc_x in enc_x_test:\n",
    "        enc_out = enc_x.dot(w) + b\n",
    "        data.append(enc_out.decrypt())\n",
    "    data = torch.tensor(data)\n",
    "    mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "    plot_normal_dist(mean, var)\n",
    "    print(\"Distribution on encrypted data:\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data falls into $[-5,5]$, the sigmoid approximation should be good enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally reached the last part, which is about training an encrypted logistic regression model on encrypted data! You can see that we decrypt the weights and re-encrypt them again after every epoch, this is necessary since after updating the weights at the end of the epoch, we can no longer use them to perform enough multiplications, so we need to get them back to the initial ciphertext level. In a real scenario, this would translate to sending the weights back to the secret-key holder for decryption and re-encryption. In that case, it will result in just a few Kilobytes of communication per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████▋                 | 49/100 [20:45:39<21:36:30, 1525.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m t_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m enc_x, plain_x ,enc_y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(enc_x_train, x_train2, enc_y_train):\n\u001b[0;32m---> 36\u001b[0m     enc_out \u001b[38;5;241m=\u001b[39m \u001b[43meelr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplain_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     eelr\u001b[38;5;241m.\u001b[39mbackward(enc_x, plain_x, enc_out, enc_y)\n\u001b[1;32m     38\u001b[0m eelr\u001b[38;5;241m.\u001b[39mupdate_parameters()\n",
      "Cell \u001b[0;32mIn[17], line 24\u001b[0m, in \u001b[0;36mEncryptedLR.forward\u001b[0;34m(self, enc_x, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, enc_x, x):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     tmp1 \u001b[38;5;241m=\u001b[39m \u001b[43menc_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     tmp2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2))\n\u001b[1;32m     26\u001b[0m     enc_out \u001b[38;5;241m=\u001b[39m tmp1 \u001b[38;5;241m+\u001b[39m tmp2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m~/anaconda3/envs/ts/lib/python3.8/site-packages/tenseal/tensors/ckksvector.py:135\u001b[0m, in \u001b[0;36mCKKSVector.dot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdot\u001b[39m(\u001b[38;5;28mself\u001b[39m, other) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCKKSVector\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    134\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dot(other)\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_list = []\n",
    "\n",
    "LR_time = []\n",
    "LR_mem = []\n",
    "LR_mem_sub = []\n",
    "\n",
    "sfm_s = memory_usage()\n",
    "\n",
    "for iter in tqdm(range(100)):\n",
    "    # eelr = EncryptedLR(lr)\n",
    "    # eelr.encrypt(ctx_training)\n",
    "    # # encrypted_out_distribution(eelr, enc_x_train)\n",
    "    mem_buff = {}\n",
    "    mem_flag[0] = True\n",
    "    st = time()\n",
    "    t = threading.Thread(target = record_mem)\n",
    "    t.start()\n",
    "\n",
    "    \n",
    "    eelr = EncryptedLR(LR(n_features), pinx, ninx)\n",
    "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "    # print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
    "    \n",
    "    times = []\n",
    "    accuracy_list = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        eelr.encrypt(ctx_training)\n",
    "        \n",
    "        # if you want to keep an eye on the distribution to make sure\n",
    "        # the function approximation is still working fine\n",
    "        # WARNING: this operation is time consuming\n",
    "        # encrypted_out_distribution(eelr, enc_x_train)\n",
    "        \n",
    "        t_start = time()\n",
    "        for enc_x, plain_x ,enc_y in zip(enc_x_train, x_train2, enc_y_train):\n",
    "            enc_out = eelr.forward(enc_x, plain_x)\n",
    "            eelr.backward(enc_x, plain_x, enc_out, enc_y)\n",
    "        eelr.update_parameters()\n",
    "        t_end = time()\n",
    "        times.append(t_end - t_start)\n",
    "        \n",
    "        eelr.decrypt()\n",
    "        \n",
    "        weight_cat = eelr.cat_weight()\n",
    "        accuracy = eelr.plain_accuracy2(x_test, y_test, weight_cat)\n",
    "        # print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
    "    \n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "    # print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "    # print(f\"Final accuracy is {accuracy}\")\n",
    "    \n",
    "    # diff_accuracy = plain_accuracy - accuracy\n",
    "    # print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "    # if diff_accuracy < 0:\n",
    "        # print(\"Oh! We got a better accuracy when training on encrypted data! The noise was on our side...\")\n",
    "\n",
    "    main_list.append(accuracy_list)\n",
    "\n",
    "    et = time()\n",
    "    mem_flag[0] = False\n",
    "    t.join()\n",
    "    \n",
    "    ft = et-st\n",
    "    fm = mem_buff[max(mem_buff)]-mem_buff[min(mem_buff)]\n",
    "\n",
    "    fm_s = memory_usage()\n",
    "    LR_time.append(ft)\n",
    "    LR_mem.append(fm)\n",
    "    LR_mem_sub.append(fm_s)\n",
    "\n",
    "print(\"LR_time : \", np.mean(LR_time))\n",
    "print(\"====================\")\n",
    "print(\"LR_mem mean : \", np.mean(LR_mem))\n",
    "print(\"LR_mem sum : \", np.sum(LR_mem))\n",
    "print(\"LR_mem max : \", max(LR_mem), \"   LR_mem min : \", min(LR_mem))\n",
    "print(\"LR_mem : \", LR_mem)\n",
    "\n",
    "print(\"====================\")\n",
    "print(\"LR_mem_sub : \", np.mean(LR_mem_sub))\n",
    "print(\"LR_mem_first : \", sfm_s )\n",
    "print(\"LR_mem_last : \", LR_mem_sub[-1])\n",
    "print(\"LR_mem_sub : \", LR_mem_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after running this cell many times myself, I always feel the joy when I see it working on encrypted data, so I hope you are feeling this joy as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in main_list:\n",
    "    a += i[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = 0\n",
    "zero = 0\n",
    "for i in y_test:\n",
    "    if 1 == i[0]:\n",
    "        one += 1\n",
    "    elif 0 == i[0]:\n",
    "        zero += 1\n",
    "\n",
    "print(\"0 : \", zero)\n",
    "print(\"1 : \", one)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
